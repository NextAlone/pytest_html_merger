import argparse
import json
import os
import pathlib
import sys

from bs4 import BeautifulSoup

import version as version_mod

CUR_PATH = "{0}/".format(os.path.dirname(__file__))

sys.path.append(CUR_PATH)


def merge_html_files(in_path, out_path):
    paths = get_html_files(in_path)
    if not paths:
        raise RuntimeError(f"Was unable to find html files in {in_path}")

    assets_dir_path = get_assets_path(in_path)

    first_file = BeautifulSoup(
        "".join(open(paths[0], encoding="utf-8")), features="html.parser"
    )

    try:
        first_file.find("link").decompose()
    except:
        pass

    if assets_dir_path is None:
        print(
            f"Will assume css is embedded in the reports. If this is not the case, "
            f"Please make sure that you have 'assets' directory inside {in_path} "
            f"which contains css files generated by pytest-html."
        )
    else:
        with open(os.path.join(assets_dir_path, "style.css"), "r") as f:
            content = f.read()

            head = first_file.head
            head.append(first_file.new_tag("style", type="text/css"))
            head.style.append(content)

    dataset = first_file.find("div", {"id": "data-container"})
    dataset_json = json.loads(dataset.attrs["data-jsonblob"])
    dataset_json["title"] = os.path.basename(out_path)

    for path in paths:
        if path == paths[0]:
            continue

        second_file = BeautifulSoup(
            "".join(open(path, encoding="utf-8")), features="html.parser"
        )
        res = second_file.find("div", {"id": "data-container"})
        dataset_json2 = res.attrs["data-jsonblob"]
        dataset_json2 = json.loads(dataset_json2)
        dataset_json["tests"] = {**dataset_json["tests"], **dataset_json2["tests"]}
        dataset_json["collectedItems"] += dataset_json2["collectedItems"]

    first_file.find("div", {"id": "data-container"}).attrs[
        "data-jsonblob"
    ] = json.dumps(dataset_json)
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(str(first_file))


def get_html_files(path):
    onlyfiles = []

    for p in pathlib.Path(path).rglob("*.html"):
        res = str(p.absolute())
        if "merged.html" in res:
            continue

        tmp = BeautifulSoup(
            "".join(open(res, encoding="utf-8")), features="html.parser"
        )
        p = tmp.find("p")
        if p and "Report generated on " in p.text:
            onlyfiles.append(res)

    return onlyfiles


def get_assets_path(path):
    res = None

    for p in pathlib.Path(path).rglob("assets"):
        return str(p.absolute())

    return res


def parse_user_commands(command_line):
    parser = argparse.ArgumentParser("pytest_html_merger")

    parser.add_argument(
        "--version", "-v", action="version", version=version_mod.version
    )

    parser.add_argument(
        "-i",
        "--input",
        default=os.path.abspath(os.path.dirname(__file__)),
        help="",
    )
    parser.add_argument(
        "-o",
        "--output",
        default=os.path.join(os.path.abspath(os.path.dirname(__file__)), "merged.html"),
        help="",
    )

    args = parser.parse_args(command_line)

    return args


def main(command_line=None):
    args = parse_user_commands(command_line)

    merge_html_files(args.input, args.output)


if __name__ == "__main__":
    main()
